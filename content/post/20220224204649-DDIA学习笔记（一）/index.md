---
title: "DDIA学习笔记（一）"
slug: DDIA学习笔记（一）
date: 2022-02-24T20:46:49+08:00
draft: true
---

<!--more-->

# 前言

很早就买了*Designing Data-Intensive Applications*在书柜吃灰，偶然一天晚上打开看了一下就被内容吸引了，于是每天晚上回家第一件事就是看几节。这里用博客记录下阅读时的一些笔记和感悟。

# Chapter 1. Reliable, Scalable, and Maintainable Applications

针对目前市面上的很多数据库应用，这本书从不同的角度分析这些应用的设计思路以及想要解决的问题，帮助我们更好地利用这些应用解决手头上的问题。

这本书主要关注数据系统以下三个方面：

1. 可靠性：在遇到问题时，系统能否继续正常工作。
2. 可扩展性：随着系统grow，系统自身需要有合理的机制来应对这个增长。
3. 可维护性：不同角色都能高效的使用系统

## 可靠性

## 可扩展性

## 可维护性

# Chapter 2. Data Models and Query Languages

在编写程序时的一个常用的方法是，对软件进行分层，不同层处理不同层的业务。层与层之间通过协议相互交流，而协议其实就是定义了一个数据模型。一个典型的应用结构如下图所示：

{{< tfigure src="images/[ch2]application-layer.jpg" title="" width="70%" class="align-center">}}

本章主要关注第二层结构，介绍一些通用的数据结构。

## Relational Model Versus Document Model

目前最常见的数据模型就是SQL，基于关系模型：数据通过关系组织，而每个关系中由许多无序的元组组成（关系就是表，元组就是行）。除了关系模型外，还有network Model、hierarchical model等。

如今我们通常用面向对象的方式来设计程序，而对象和SQL中的关系不会严格的对应。二者之间通常由一层ORM层进行转换，但是二者之间的不匹配没有完全地解决。例如如果一个简历上有人的基本信息、工作经历、教育经历等信息。其中工作经历和教育经历通常有多个。因此基本信息和这两个经历的关系就是一对多的关系。如果我们用关系模型来存储，通常有三种方案：

1. 传统SQL模型，将三个信息存储到三个表中，使用一个外键来指向user表。
2. 将这些信息以json、xml的形式存储到一行中，使用SQL新特性来检索其中的信息。
3. 将这些信息表示为json、xml，然后以text的形式存储到一行中，这种方法需要程序自己处理里面的数据。

但是其实对于简历这种数据来说，非常容易使用json、xml等格式直接存储，使用document-oriented的数据库就非常合适。

但是json、xml这种文档类型的数据模型也有其缺陷，他们不擅长处理的是多对多或多对一的关系。还是看简历这个例子，假设简历中有base地信息，那么不同的人可能位于不同或相同的城市。在SQL模型中，我们通常使用一个单独的表来存储城市信息，然后在简历表中用一个cityId指向这个城市。在SQL中这么做的好处是，如果城市的名称等信息发生变化，我们只需要修改城市表中对应行的信息即可。在SQL中查询也只需要一次JOIN操作即可。但是对于文档类型的数据模型，如果我们也使用这种引用的方式，那么每次在查询时，都需要进行多次查询才能查到一份简历的完整信息。所以，文档类型的数据模型并不擅长处理JOIN操作。

那么什么时候使用关系型，什么时候使用文档型结构呢？下面是一个对比：

|                | 简单易用                     | 数据模式灵活性                                               | 数据局部性                                                   | 相同点                                      |
| -------------- | ---------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------- |
| 文档型 | 数据中只存在一对多的关系；   | 文档型数据库不强制要求数据的结构；数据结构发生变化时，可以直接写入，但是在代码中需要做兼容；当数据结构不确定是适合使用文档型。 | 文档型结构中通常会将数据存储到一起，因此在查全量数据时可以更好的利用局部性原理。但是如果只查询或修改文档的一小部分，仍需要查询全部的数据，回廊分性能。 | 文档型数据库正在逐渐支持join的查询。        |
| 关系型 | 数据中有多对多、多对一的关系 | 在写入时会严格检车数据的格式；数据结构发生变化时，需要手动调整表结构再修改代码；当数据结构明确时适合关系型。 | 在查询全部数据时，会查询多个索引。在一些关系数据库中，也会使用一些技术将类似的数据放到一起，更好的利用局部性原理。 | 关系型数据库也在逐渐支持对json、xml的支持。 |

## Query Languages for Data

关系型数据库通常使用SQL语句来查询，SQL语句属于一种声明式的查询语句；而文档型数据库通常需要程序要自己编写查询条件等查询语句，属于一种过程式的查询语句。

声明式语句比过程式语句有许多优点。首先，声明式语句只需要告诉数据库引擎自己需要什么类型的数据即可，数据库引擎屏蔽了查询的细节，能够让引擎在不改变查询条件的情况下优化性能；SQL语句查询的结果是不保证有序的，因此留了许多优化的空间；最后，由于查询过程不可见，因此数据库引擎内可以很方便的利用并行来查询数据。

MapReduce是另一种查询语言，通常用于查询分布在多个计算机节点、大批量数据的场景下。一些NoSQL数据库实现了一个受限的MapReduce版本，用于实现多个文档的查询场景下。MapReduce的核心是需要实现Map和Reduce函数。在Map函数中处理每条数据，然后生成一个(k,v)键值对，然后将相同key的值聚合到一起调用reduce方法。在Map和Reduce中，只能实现数据的处理，不能对数据进行写入操作。

## Graph-Like Data Models

文档型数据模型通常适合处理一对多或无关系的结构，关系型数据模型适合处理多对一及少量多对多的结构。当数据全为多对多的关系时，更适合使用图数据模型。

# Chapter 3. Storage and Retrieval

本章讨论的是，如何实现数据的存储和访问。

## Data Structures That Power Your Database

数据存储并没有特别复杂，最简单的方式就是顺序向一个文件中写入，在读取时从文件开始查找即可。如果数据量较小，那么这种方式性能很高，因为写入是顺序的硬盘不需要寻道；查找速度也不会太慢。但是随着数据量增多，写入的内容越来越多，写入的速度不会太慢，但是读取会很慢，时间复杂度为O(n).此时我们就需要一种结构——索引，来加快查找速度。在添加索引后，由于写入时还需要写入索引，因此写速度会相应变慢。

### Hash Index

考虑Key-Value数据库。数据库仍然是顺序向文件写入。在对文件内的值建立索引最简单的方式是，在内存内保存一个哈希表，value为对应值在硬盘上的位置。没当新增一个值，就向文件中写入一条记录，然后更新内存中的值。

由于我们是一直追加写入，因此文件会不断变大，如何避免硬盘被写满呢？一种方式是将存储数据的文件分片。写入文件时，当文件的大小过大，则关闭该文件，然后写入一个新的文件。当文件数量超过一个阈值或可以定期对这些小文件进行合并。合并过程中使用旧文件查询，合并结束后使用新文件。

为什么采用追加方式？

1. 写入数据和合并数据段都是顺序操作，比随机读写快
2. 并发控制和crash recovery更简单。
3. 在合并文件时不需要考虑合并时旧文件的修改问题。

哈希索引的一些缺陷：

1. 哈希表只能存储在内存中，哈希表的大小受限制于内存大小
2. 对顺序查询的支持不友好

### SSTables and LSM-Trees

下面我们对存储在硬盘上的数据做一个修改，要求存储的数据必须是有序的，我们称之为SSTable（Sorted String Table）。存储数据变为有序后，比哈希索引的优势在于：

1. 文件合并过程更为简单有效，允许文件大小比内存大小更大。由于段都为有序的，因此合并过程可以看作是归并排序的过程。如果一个Key在多个文件中存在，那么保留最新的文件中的值即可。
2. 不必在内存中保存所有的索引。只保留某些索引，然后找到一个区间，在区间内查找即可（类似调跳表）
3. 如果使用范围查找，那么范围内的数据可以进行压缩。

那么如何构造这样的文件结构呢？我们知道，在硬盘中构造有序很难，但在内存中很简单（红黑树or AVL树）。那么我们可以在内存中先构建一个有序的树结构，当这个树大于一定的大小时，将其写入到硬盘上。

主要流程变为：
1. 写入时，先写入内存的树中，树称为memtable
2. memtable大于一定的值时，写入硬盘作为SSTable
3. 查找时，先找memtable，然后按时间顺序查找硬盘中的SSTable
4. 使用一个后台线程进行SSTable的合并。

由于我们在内存中保存数据，因此如果server down了，内存中的数据就会丢失，所以我们可以先记录一个写入log，供断电后恢复。

使用多个SSTable构成的存储引擎，我们称作Log-Structured Merge-Tree，LSM-Tree。

性能提升点：
1. 使用布隆过滤器快速判断key是否存在
2. 基于大小或层的方式合并SSTable

### B-Trees

LSM-Tree是将数据库分成多个segment file，而B-Trees是将数据库分成一个个Pages，大小通常为4KB，在数据读写时都是以Page为最小单位进行的。Page之间通过引用连接到一起，最终组合成了一棵树。

每个Page中存储的Key都是一个个区间范围，查找时从树根开始查，然后逐步找到对应的元素。写入时也是找到要写入的Page，修改Page内容之后，就讲该Page写入到硬盘上。如果key过大，一页分不下，就需要对当前的Page进行分裂。

由于修改Page的过程都是原地进行的，因此如果在这个过程中有硬件问题，很容易出现数据丢失，为了确保数据的正确性，通常在写入数据时还写入一个write-ahead log。

B-Trees的一些优化：

1. 使用copy-on-write机制确保数据不丢失
2. 缩短key的大小，只保留能进行范围查找的内容
3. 让key相连的page尽可能存储到一起，避免硬盘寻道的问题
4. 树的叶子结点通过额外的指针相连，范围查找时可以不再经过父节点
5. 差分树

### LSM tree与B-tree的比较

B-tree在每次写入数据的时候都会写入两次硬盘，一次是写日志，一次是写入page。LSM-tree是写入时一次，在合并时在写入一次。LSM-tree比B-tree有更高的write throughput。

LSM-tree是顺序写入文件，因此磁盘利用率更高。而B-tree写入是按页写入，一页可能没有写满就会分页。

由于LSM-tree会进行归并操作，这个过程会占用带宽，因此会影响现有的写入和读取操作。另外如果归并操作的频率小于新数据写入的频率，最终磁盘也会被打满。

B-tree的好处在于，每个key只会在硬盘中存储一次。可以直接对索引树加锁，方便事务的隔离操作。

## Transaction Processing or Analytics

Transaction Processing是指用户可以低延迟的完成读写操作，并不一定需要有ACID属性；与之相对的是Batch Processing，周期执行，每次执行时间较长。

用户在使用索引来对某几条数据进行增删改查的操作称之为online transaction processing（OLTP）；而范围查询大批量数据进行分析的操作称为online analytic processing (OLAP)。

OLTP通常要求快速低延迟的完成数据操作，因此通常不在OLTP数据库上进行大规模数据的分析操作。为了实现大规模数据分析，衍生出data warehouse，数仓这个产品。数仓中的数据是OLTP数据库的一个拷贝，通过ETL完成。在数仓中完成OLAP操作可以避免对OLTP数据库产生影响。

另外，由于OLTP和OLAP的侧重点不同，因此这两种数据库的实现方式、优化方式也不同。OLTP与OLAP之间的区别：

| Property | OLTP | OLAP |
|----------|------|------|
|      读模式    |   每次利用索引读取少量数据   |  每次聚合大量数据    |
|      写模式    |    随机、低延迟写入  |   通过ETL或事件系统大规模导入   |
|     主要用于     |   给终端用户使用   |  内部数据分析    |
|     数据内容     |   最新的数据   |   历史数据   |
| 数据量 | GB - TB | TB - PB |

与OLAP数据库对应的数据模型只有两种：星状模型和雪花模型。星状模型是指，使用一个事实表来存储发生的事件，事实表中存储的都是外键，外键是周围维表的主键。维表中包含的是数据的真正含义。而雪花模型是指，维表可以继续使用外键来索引其他表。

## Column-Oriented Storage

对于数据仓库来说，事实表通常有万亿的数据量，每行数据有几百列。但是每次查询时我们可能只需要其中的某几列数据。如果使用关系行数据库，我们需要先把一行中所有的数据都查出来，然后过滤出其中的几列。关系型数据库查询数据耗费时间的原因是，存储引擎是按行组织数据，将一行数据存放到一起。为了提高查询速度我们可以按列存储，将每一列的数据存储到一个单独的文件中，然后查询的时候查各自的文件即可。

使用按列存储的另一个好处是，可以有效的对数据进行压缩。因为虽然事实表的数量很多，但是维表中的数据通常很少。例如有一个维表是国家表，那么这个表的数据量就会很小，那么事实表中存储该值的列就会有大量的重复，可以很方便的进行数据压缩。

两种常见的数据压缩方式：bitmap和run-length encoding。

{{< tfigure src="images/[ch3]bitmap.png" title="" width="50" class="align-center">}}

其中bitmap中每一列代表一个数字，每一列中每个哪一位为1代表该列的值是多少。使用bitmap还可以方便的进行in和and操作。可以直接转换为and和or的位运算。

在按列存储数据时，我们没有对列中的数据进行排序。但我们可以选择在存储时按某一列进行排序，这么做的好处有两个，一个是可以加快范围查找的速度，减少加载数据的数量；另一个是排序后相同的数据聚合到一起了，更容易实现数据的压缩了。

使用列存储的一个缺点在于，如果有一次写入，那么必须写入每一个列文件。如果列数据是有序的，那气势我们可以将数据先写入内存的一个SSTable里，再和硬盘上的数据合并。

# Chapter 4. Encoding and Evolution

随着需求的更新，软件也在不断的迭代，随之而来的是数据模型的变更。数据的变更带来了兼容性问题：

1. 为了保证服务端变更的平滑，通常先升级某些服务端版本，稳定后再更新其他版本。
2. 而客户端用户通常不会立刻升级。

这就造成在软件升级的一段时间内，老的数据模型和新的数据模型会是共存的。因此，在软件升级的过程中，数据模型必须保证**前向兼容**和**后向兼容**：

1. 前向兼容是指旧代码可以解析和读取新的数据模型；
2. 向后兼容是指新的代码可以解析和读取旧的数据模型。

本章主要介绍，当前常见的数据编码方式及他们是如何做到向前和向后兼容的。

## 数据编码方式

数据在内存中以树、链表、字典等数据结构存储，当需要将数据永久保存到磁盘上或通过网络发送给其他进程时，需要某种编码方式对这些数据进行编码。

### 特定语言的数据编码

有些编程语言中内置了编码方式，例如Java中的java.io.Serializable，Python中的pickle等。这些编码的好处是，不需要额外的编程；缺点是：

1. 与特定的语言绑定，一般只能由使用该语言的进程进行编解码；
2. 安全性问题，反序列化过程需要生成任意的类，这个过程可能会受到恶意攻击；
3. 兼容性问题，对向前和向后兼容做的不好
4. 性能问题，这些库是公共的，因此在某些特定的场景下性能不好

### Json，XML及其二进制变种

Json、XML、CSV都是一些与语言无关的编码方式。这些方式的一些缺点在于：

1. 对数字的编码不友好。XML无法区分数字和字符串，而JSON无法区分浮点和整型。
2. 不支持二进制字符串。一个折中的办法是将二进制字符串变成base64作为字符串存储在xml和json中。
3. xml和json对数据schema的支持过于复杂
4. CSV没有schema，因此添加和删除列都需要编码。

XML、JSON、CSV多用于组织之间的数据交换。因为组织间的数据交换更多的是在形式上达成一致，通常不考虑性能。